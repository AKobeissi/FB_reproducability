{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Placeholder to ensure next edit works\n",
        ""
      ],
      "id": "4550c50d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [],
      "id": "67283726"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import glob\n",
        "print(glob.glob(\"FB_REPRODUCABILITY/*\"))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d60e8c87"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import pickle\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm \n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "#LangChain Stuff\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma   # type: ignore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_classic.chains import RetrievalQA\n",
        "# LangChain Model Wrappers\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.schema import HumanMessage\n",
        "# from langchain.chat_models import ChatAnthropic\n",
        "from langchain_community.llms import Replicate\n",
        "\n",
        "# Model Providers\n",
        "import openai\n",
        "# import anthropic\n",
        "import replicate\n",
        "import tiktoken\n",
        "\n",
        "# # import ANTHROPIC TOKENIZER\n",
        "# CLIENT = anthropic.Anthropic(api_key=os.environ['ANTHROPIC_API_KEY'])\n",
        "# anthropic_tokenizer = CLIENT.get_tokenizer()\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "2eded323"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##############################################################################\n",
        "# MODEL CONFIGS\n",
        "##############################################################################\n",
        "configs = [\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4o-2024-05-13\",   \"eval_mode\":\"singleStore\",        \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4o-2024-05-13\",   \"eval_mode\":\"sharedStore\",        \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4o-2024-05-13\",   \"eval_mode\":\"inContext\",          \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4o-2024-05-13\",   \"eval_mode\":\"inContext_reverse\",  \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4o-2024-05-13\",   \"eval_mode\":\"oracle\",             \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4o-2024-05-13\",   \"eval_mode\":\"oracle_reverse\",     \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4o-2024-05-13\",   \"eval_mode\":\"sharedStore\",        \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4-1106-preview\",  \"eval_mode\":\"sharedStore\",        \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4-1106-preview\",  \"eval_mode\":\"singleStore\",        \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4-1106-preview\",  \"eval_mode\":\"inContext\",          \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4-1106-preview\",  \"eval_mode\":\"closedBook\",         \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            # {\"provider\": \"anthropic\",  \"model_name\":\"claude-2\",            \"eval_mode\":\"inContext\",          \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4-1106-preview\",  \"eval_mode\":\"oracle\",             \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"replicate\",  \"model_name\":\"llama2\",              \"eval_mode\":\"sharedStore\",        \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"replicate\",  \"model_name\":\"llama2\",              \"eval_mode\":\"singleStore\",        \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4\",               \"eval_mode\":\"sharedStore\",        \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4\",               \"eval_mode\":\"singleStore\",        \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4\",               \"eval_mode\":\"closedBook\",         \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4\",               \"eval_mode\":\"oracle\",             \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4-1106-preview\",  \"eval_mode\":\"oracle_reverse\",     \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            # {\"provider\": \"anthropic\",  \"model_name\":\"claude-2\",            \"eval_mode\":\"oracle_reverse\",     \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"openai\",     \"model_name\":\"gpt-4-1106-preview\",  \"eval_mode\":\"inContext_reverse\",  \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            # {\"provider\": \"anthropic\",  \"model_name\":\"claude-2\",            \"eval_mode\":\"inContext_reverse\",  \"temp\":0.01,   \"max_tokens\":2048},\n",
        "            {\"provider\": \"\",           \"model_name\":\"\",                    \"eval_mode\":\"singleStore\",        \"temp\":None,   \"max_tokens\":None},       # SPECIAL MODE --> RETRIEVAL ONLY MODE (SINGLE STORE)\n",
        "            {\"provider\": \"\",           \"model_name\":\"\",                    \"eval_mode\":\"sharedStore\",        \"temp\":None,   \"max_tokens\":None},       # SPECIAL MODE --> RETRIEVAL ONLY MODE (SHARED STORE)\n",
        "]\n",
        "\n",
        "replicate_model_mapping = dict({\n",
        "            \"llama2\": \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\"\n",
        "        })\n",
        "\n",
        "##############################################################################\n",
        "# DATASET CONFIG\n",
        "##############################################################################\n",
        "PATH_CURRENT = os.path.abspath(os.getcwd())\n",
        "PATH_DATASET_JSONL = PATH_CURRENT + \"/data/financebench_open_source.jsonl\"\n",
        "PATH_DOCUMENT_INFO_JSONL = PATH_CURRENT + \"/data/financebench_document_information.jsonl\"\n",
        "PATH_RESULTS = PATH_CURRENT + \"/results/\"\n",
        "PATH_PDFS = PATH_CURRENT + \"/pdfs/\"\n",
        "\n",
        "# Choose DATASET PORTION:\n",
        "# - ALL: Full Dataset\n",
        "# - OPEN_SOURCE: Open Source Part (n=150)\n",
        "# - CLOSED_SOURCE: Closed Source Part --> Request access at contact@patronus.ai\n",
        "DATASET_PORTION = \"OPEN_SOURCE\"   \n",
        "\n",
        "##############################################################################\n",
        "# VECTOR STORE SETUP\n",
        "##############################################################################\n",
        "VS_CHUNK_SIZE = 1024\n",
        "VS_CHUNK_OVERLAP = 30\n",
        "VS_DIR_VS = PATH_CURRENT + \"/vectorstores\""
      ],
      "execution_count": 25,
      "outputs": [],
      "id": "227a01d7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "PATH_DOCUMENT_INFO_JSONL\n",
        "/u/kobeissa/Documents/thesis/experiments/FB_reproducability/data/financebench_document_information.jsonl"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/u/kobeissa/Documents/thesis/experiments/FB_reproducability/data/financebench_document_information.jsonl'"
            ]
          }
        }
      ],
      "id": "52d31b68"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##############################################################################\n",
        "# LOAD DATASET\n",
        "##############################################################################\n",
        "\n",
        "# Load Full Dataset \n",
        "df_questions = pd.read_json(PATH_DATASET_JSONL, lines=True)\n",
        "df_meta = pd.read_json(PATH_DOCUMENT_INFO_JSONL, lines=True)\n",
        "df_full = pd.merge(df_questions, df_meta, on=\"doc_name\")\n",
        "\n",
        "# Get all docs\n",
        "df_questions = df_questions.sort_values('doc_name')\n",
        "ALL_DOCS = df_questions['doc_name'].unique().tolist()\n",
        "print(f\"Total number of distinct PDF: {len(ALL_DOCS)}\")\n",
        "\n",
        "# Select relevant dataset portion\n",
        "if DATASET_PORTION != \"ALL\":\n",
        "    df_questions = df_questions.loc[df_questions[\"dataset_subset_label\"]==DATASET_PORTION]\n",
        "print(f\"Number of questions: {len(df_questions)}\")\n",
        "\n",
        "# Check relevant documents\n",
        "df_questions = df_questions.sort_values('doc_name')\n",
        "docs = df_questions['doc_name'].unique().tolist()\n",
        "print(f\"Number of distinct PDF: {len(docs)}\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of distinct PDF: 84\n",
            "Number of questions: 150\n",
            "Number of distinct PDF: 84\n"
          ]
        }
      ],
      "id": "985e340b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##############################################################################\n",
        "# HELPER FUNCTIONS (PDF-PARSING + VECTOR-STORE SETUPS)\n",
        "##############################################################################\n",
        "def get_pdf_text(doc):\n",
        "    \n",
        "    path_doc = f\"{PATH_PDFS}/{doc}.pdf\"\n",
        "    pdf_reader = PyMuPDFLoader(path_doc)\n",
        "    pdf_text = pdf_reader.load()\n",
        "\n",
        "    return pdf_text\n",
        "\n",
        "def build_vectorstore_retriever(docs, embeddings = OpenAIEmbeddings()):\n",
        "\n",
        "    if docs == \"all\":\n",
        "        docs = ALL_DOCS\n",
        "        db_path = VS_DIR_VS + \"/shared\"\n",
        "    else:\n",
        "        docs = [docs]\n",
        "        db_path = VS_DIR_VS + \"/\" + docs[0]\n",
        "    \n",
        "    # Create Vector Store if not already existing\n",
        "    if not os.path.exists(db_path):\n",
        "        \n",
        "        # Create folder for vector store\n",
        "        os.mkdir(db_path) \n",
        "\n",
        "        # Create vector store itself --> chrom.sqlite3 database\n",
        "        if not os.path.exists(f\"{db_path}/chroma.sqlite3\"):\n",
        "            vectordb = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
        "            vectordb.persist()\n",
        "    \n",
        "            # Add Documents to Vector store    \n",
        "            for doc in docs:\n",
        "                pdf_text = get_pdf_text(doc)\n",
        "                text_splitter = RecursiveCharacterTextSplitter(\n",
        "                    chunk_size = VS_CHUNK_SIZE,\n",
        "                    chunk_overlap = VS_CHUNK_OVERLAP,\n",
        "                )\n",
        "                splitted_texts = text_splitter.split_documents(pdf_text)\n",
        "        \n",
        "                # Add to vector store\n",
        "                vectordb.add_documents(documents=splitted_texts)\n",
        "                vectordb.persist()\n",
        "\n",
        "    else:\n",
        "        vectordb = Chroma(persist_directory=db_path, embedding_function=embeddings)\n",
        "\n",
        "    return vectordb.as_retriever(), vectordb\n",
        "\n",
        "##############################################################################\n",
        "# MODEL + CALL HANDLERS\n",
        "##############################################################################\n",
        "\n",
        "def get_max_context_length(prompt, anthropic_cutoff=95000, openai_cutoff=105000):\n",
        "\n",
        "    # # (0) Check Anthropic Tokenizer\n",
        "    # tokens_anthropic = anthropic_tokenizer.encode(prompt)\n",
        "    # nb_tokens_anthropic = len(tokens_anthropic)\n",
        "    # number_of_chars_anthropic = len(prompt)\n",
        "    \n",
        "    # if nb_tokens_anthropic > anthropic_cutoff:\n",
        "    #     tokens_anthropic_tokens = tokens_anthropic.tokens\n",
        "    #     token_lengths_anthropic = [len(token) for token in tokens_anthropic_tokens]\n",
        "    #     number_of_chars_anthropic = sum(token_lengths_anthropic[:anthropic_cutoff])\n",
        "        \n",
        "\n",
        "    # (1) Check OpenAI Tokenizer\n",
        "    tokenizer_openai = tiktoken.encoding_for_model(\"gpt-4-1106-preview\")\n",
        "    tokens_openai = tokenizer_openai.encode(prompt)\n",
        "    nb_tokens_openai = len(tokens_openai)\n",
        "    number_of_chars_openai = len(prompt)\n",
        "\n",
        "    if nb_tokens_openai > openai_cutoff:\n",
        "        tokens_openai_tokens = [tokenizer_openai.decode_single_token_bytes(token) for token in tokens_openai]\n",
        "        token_lengths_openai = [len(token) for token in tokens_openai_tokens]\n",
        "        number_of_chars_openai = sum(token_lengths_openai[:openai_cutoff])\n",
        "\n",
        "    # Cut prompt depending on minimal length limit\n",
        "    number_of_chars = min(number_of_chars_openai)\n",
        "\n",
        "    return number_of_chars\n",
        "\n",
        "def get_model(provider=\"openai\", model_name=\"gpt-4\", temp=0.01, max_tokens=2048):\n",
        "\n",
        "    if provider == \"openai\":\n",
        "        return ChatOpenAI(\n",
        "            model_name=model_name, \n",
        "            temperature=temp, \n",
        "            max_tokens=max_tokens\n",
        "            )\n",
        "        \n",
        "    # elif provider == \"anthropic\":\n",
        "    #     return ChatAnthropic(\n",
        "    #         model=model_name,\n",
        "    #         temperature=temp, \n",
        "    #         max_tokens_to_sample=max_tokens, \n",
        "    #         anthropic_api_key=os.environ['ANTHROPIC_API_KEY']\n",
        "    #         )\n",
        "    \n",
        "    elif provider == \"replicate\":\n",
        "        if model_name in replicate_model_mapping:\n",
        "            return Replicate(\n",
        "                model=replicate_model_mapping[model_name],\n",
        "                model_kwargs={\n",
        "                    'temperature': temp, \n",
        "                    'max_new_tokens': max_tokens\n",
        "                    },\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(\"Unknown Model\")\n",
        "        \n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_answer(model, eval_mode, question, context, retriever, retriever_only=False):\n",
        "\n",
        "    retrieved_documents = []\n",
        "\n",
        "    if eval_mode == \"closedBook\":\n",
        "        prompt = f\"Answer this question: {question}\"\n",
        "        answer = model.predict(prompt)\n",
        "        \n",
        "    elif eval_mode == \"oracle\":\n",
        "        prompt = f\"Answer this question: {question} \\nHere is the relevant evidence that you need to answer the question:\\n[START OF FILING] {context} [END OF FILING]\"\n",
        "        answer = model.predict(prompt)\n",
        "\n",
        "    elif eval_mode == \"oracle_reverse\":\n",
        "        \n",
        "        prompt = f\"Context:\\n[START OF FILING] {context} [END OF FILING\\n\\n Answer this question: {question} \\n\"\n",
        "        answer = model.predict(prompt)\n",
        "\n",
        "    elif eval_mode in [\"inContext\",  \"inContext_reverse\"]:\n",
        "        \n",
        "        # Context Cutoff to satisfy max tokens\n",
        "        max_number_of_chars = get_max_context_length(context)\n",
        "        context = context[:max_number_of_chars]\n",
        "        \n",
        "        if eval_mode == \"inContext\":\n",
        "            prompt = f\"Answer this question: {question} \\nHere is the relevant filing that you need to answer the question:\\n[START OF FILING] {context} [END OF FILING]\"\n",
        "        else:\n",
        "            prompt = f\"Context:\\n[START OF FILING] {context} [END OF FILING]\\n\\n Answer this question: {question}\\n\"\n",
        "\n",
        "        answer = model.predict(prompt)\n",
        "\n",
        "    elif eval_mode == \"singleStore\" or eval_mode == \"sharedStore\":\n",
        "        \n",
        "        # Retrieval-only mode if model=None (No LLM calls, only queries in VectorDB)\n",
        "        if not model:           \n",
        "            prompt = f\"{question}\"\n",
        "            s = retriever.invoke(prompt)\n",
        "            return (\"\", s)\n",
        "\n",
        "        else:\n",
        "\n",
        "            # Don't add a question prefix as RetrievalQA will do some automatic prompt wrapping\n",
        "            # --> This can replace by more advanced Retrieval Strategies\n",
        "            prompt = f\"{question}\"\n",
        "            qa = RetrievalQA.from_chain_type(\n",
        "                llm=model,\n",
        "                chain_type=\"stuff\",\n",
        "                retriever=retriever,\n",
        "                return_source_documents=True,\n",
        "            )\n",
        "            s = qa(prompt)\n",
        "            \n",
        "            answer = s[\"result\"]\n",
        "            retrieved_documents = s[\"source_documents\"]\n",
        "\n",
        "\n",
        "    \n",
        "    return (answer, retrieved_documents)\n"
      ],
      "execution_count": 41,
      "outputs": [],
      "id": "09454e37"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##############################################################################\n",
        "# EVALUATION\n",
        "##############################################################################\n",
        "\n",
        "# Specify evaluation model\n",
        "model_config = configs[4] #4\n",
        "\n",
        "# Set evaluation questions\n",
        "df_eval = df_questions\n",
        "\n",
        "\n",
        "# Get the model\n",
        "model = get_model(provider=model_config[\"provider\"],\n",
        "                  model_name=model_config[\"model_name\"],\n",
        "                  temp=model_config[\"temp\"],\n",
        "                  max_tokens=model_config[\"max_tokens\"])\n",
        "\n",
        "print(f\"--> Evaluating: {model_config['model_name']} / {model_config['eval_mode']}\")\n",
        "\n",
        "last_docs = None\n",
        "results = []\n",
        "\n",
        "# Run evaluation on the model  --> Sort along doc_name to reuse retriever configs in memory\n",
        "for k, (idx, row) in tqdm(\n",
        "    enumerate(df_eval.sort_values(\"doc_name\").iterrows()),\n",
        "    total=len(df_eval)\n",
        "):        \n",
        "    \n",
        "    # (A) Setup Context or Retriever\n",
        "    if model_config[\"eval_mode\"] == \"closedBook\":\n",
        "        retriever = None\n",
        "        context = \"\"\n",
        "    \n",
        "    elif model_config[\"eval_mode\"] in [\"inContext\", \"inContext_reverse\"]:\n",
        "        retriever = None\n",
        "        docs = row[\"doc_name\"]\n",
        "        if not (last_docs == docs):\n",
        "            pages = get_pdf_text(row[\"doc_name\"])\n",
        "            context = \"\\n\\n\".join([page.page_content for page in pages])\n",
        "            \n",
        "    \n",
        "    elif model_config[\"eval_mode\"] in [\"oracle\", \"oracle_reverse\"]:\n",
        "        context = \"\\n\\n\".join([evidence[\"evidence_text_full_page\"] for evidence in row[\"evidence\"]])\n",
        "        retriever = None\n",
        "\n",
        "    elif model_config[\"eval_mode\"] in [\"singleStore\", \"sharedStore\"]:\n",
        "        context = \"\"\n",
        "        docs = \"all\"\n",
        "\n",
        "        if model_config[\"eval_mode\"] == \"singleStore\":\n",
        "            docs = row[\"doc_name\"]\n",
        "        \n",
        "        if not (last_docs == docs):\n",
        "            retriever, _ = build_vectorstore_retriever(docs=docs)\n",
        "            last_docs = docs\n",
        "\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unknown 'eval_mode'!\")\n",
        "\n",
        "\n",
        "    # (B) Model Call\n",
        "    (answer, retrieved_documents) = get_answer(\n",
        "                                        model=model, \n",
        "                                        eval_mode=model_config[\"eval_mode\"], \n",
        "                                        question=row[\"question\"], \n",
        "                                        context=context, \n",
        "                                        retriever=retriever\n",
        "                                        )\n",
        "    \n",
        "\n",
        "    # (C) Bookkeeping\n",
        "    results.append({\n",
        "                        **model_config, \n",
        "                        \"financebench_id\" : row[\"financebench_id\"],\n",
        "                        \"question\" : row[\"question\"],\n",
        "                        \"gold_answer\": row[\"answer\"],\n",
        "                        \"model_answer\": answer,\n",
        "                        \"retrieved_documents\" : retrieved_documents,\n",
        "                    })\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_csv(PATH_RESULTS + \"/\" + model_config[\"model_name\"] + \"_\" + model_config[\"eval_mode\"] + \".csv\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "9487a91f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_results_shared"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>provider</th>\n",
              "      <th>model_name</th>\n",
              "      <th>eval_mode</th>\n",
              "      <th>temp</th>\n",
              "      <th>max_tokens</th>\n",
              "      <th>financebench_id</th>\n",
              "      <th>question</th>\n",
              "      <th>gold_answer</th>\n",
              "      <th>model_answer</th>\n",
              "      <th>retrieved_documents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>openai</td>\n",
              "      <td>gpt-4o-2024-05-13</td>\n",
              "      <td>sharedStore</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2048</td>\n",
              "      <td>financebench_id_03029</td>\n",
              "      <td>What is the FY2018 capital expenditure amount ...</td>\n",
              "      <td>$1577.00</td>\n",
              "      <td>The FY2018 capital expenditure amount for 3M i...</td>\n",
              "      <td>[page_content='478 \\n— \\nOther — net\\n1 \\n31 \\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>openai</td>\n",
              "      <td>gpt-4o-2024-05-13</td>\n",
              "      <td>sharedStore</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2048</td>\n",
              "      <td>financebench_id_04672</td>\n",
              "      <td>Assume that you are a public equities analyst....</td>\n",
              "      <td>$8.70</td>\n",
              "      <td>The year-end FY2018 net property, plant, and e...</td>\n",
              "      <td>[page_content='value at both December 31, 2018...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>openai</td>\n",
              "      <td>gpt-4o-2024-05-13</td>\n",
              "      <td>sharedStore</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2048</td>\n",
              "      <td>financebench_id_00499</td>\n",
              "      <td>Is 3M a capital-intensive business based on FY...</td>\n",
              "      <td>No, the company is managing its CAPEX and Fixe...</td>\n",
              "      <td>Yes, 3M can be considered a capital-intensive ...</td>\n",
              "      <td>[page_content='In 2022, 3M expended approximat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>openai</td>\n",
              "      <td>gpt-4o-2024-05-13</td>\n",
              "      <td>sharedStore</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2048</td>\n",
              "      <td>financebench_id_01226</td>\n",
              "      <td>What drove operating margin change as of FY202...</td>\n",
              "      <td>Operating Margin for 3M in FY2022 has decrease...</td>\n",
              "      <td>The operating margin for 3M as of FY2022 was i...</td>\n",
              "      <td>[page_content='Additional information about re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>openai</td>\n",
              "      <td>gpt-4o-2024-05-13</td>\n",
              "      <td>sharedStore</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2048</td>\n",
              "      <td>financebench_id_01865</td>\n",
              "      <td>If we exclude the impact of M&amp;A, which segment...</td>\n",
              "      <td>The consumer segment shrunk by 0.9% organically.</td>\n",
              "      <td>Excluding the impact of mergers and acquisitio...</td>\n",
              "      <td>[page_content='in the third quarter of 2022.\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>openai</td>\n",
              "      <td>gpt-4o-2024-05-13</td>\n",
              "      <td>sharedStore</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2048</td>\n",
              "      <td>financebench_id_00215</td>\n",
              "      <td>Is Verizon a capital intensive business based ...</td>\n",
              "      <td>Yes. Verizon's capital intensity ratio was app...</td>\n",
              "      <td>Yes, Verizon is a capital-intensive business b...</td>\n",
              "      <td>[page_content='Capital Expenditures\\n$23,087\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>openai</td>\n",
              "      <td>gpt-4o-2024-05-13</td>\n",
              "      <td>sharedStore</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2048</td>\n",
              "      <td>financebench_id_00566</td>\n",
              "      <td>Has Verizon increased its debt on balance shee...</td>\n",
              "      <td>No. Verizon's debt decreased by $229 million.</td>\n",
              "      <td>Yes, Verizon has increased its debt on the bal...</td>\n",
              "      <td>[page_content='(3) We believe that this measur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>openai</td>\n",
              "      <td>gpt-4o-2024-05-13</td>\n",
              "      <td>sharedStore</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2048</td>\n",
              "      <td>financebench_id_06247</td>\n",
              "      <td>What is FY2018 days payable outstanding (DPO) ...</td>\n",
              "      <td>42.69</td>\n",
              "      <td>To calculate the Days Payable Outstanding (DPO...</td>\n",
              "      <td>[page_content='As of March 28, 2018 , there we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>openai</td>\n",
              "      <td>gpt-4o-2024-05-13</td>\n",
              "      <td>sharedStore</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2048</td>\n",
              "      <td>financebench_id_04784</td>\n",
              "      <td>Based on the information provided primarily in...</td>\n",
              "      <td>0.2%</td>\n",
              "      <td>To calculate the change in unadjusted operatin...</td>\n",
              "      <td>[page_content='$\\n500,343\\n$\\n485,873\\n$\\n482,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>openai</td>\n",
              "      <td>gpt-4o-2024-05-13</td>\n",
              "      <td>sharedStore</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2048</td>\n",
              "      <td>financebench_id_06741</td>\n",
              "      <td>What is the FY2018 - FY2020 3 year average una...</td>\n",
              "      <td>6.2%</td>\n",
              "      <td>To calculate the FY2018 - FY2020 3-year averag...</td>\n",
              "      <td>[page_content='$\\n500,343\\n$\\n485,873\\n$\\n482,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    provider         model_name    eval_mode  temp  max_tokens  \\\n",
              "0     openai  gpt-4o-2024-05-13  sharedStore  0.01        2048   \n",
              "1     openai  gpt-4o-2024-05-13  sharedStore  0.01        2048   \n",
              "2     openai  gpt-4o-2024-05-13  sharedStore  0.01        2048   \n",
              "3     openai  gpt-4o-2024-05-13  sharedStore  0.01        2048   \n",
              "4     openai  gpt-4o-2024-05-13  sharedStore  0.01        2048   \n",
              "..       ...                ...          ...   ...         ...   \n",
              "145   openai  gpt-4o-2024-05-13  sharedStore  0.01        2048   \n",
              "146   openai  gpt-4o-2024-05-13  sharedStore  0.01        2048   \n",
              "147   openai  gpt-4o-2024-05-13  sharedStore  0.01        2048   \n",
              "148   openai  gpt-4o-2024-05-13  sharedStore  0.01        2048   \n",
              "149   openai  gpt-4o-2024-05-13  sharedStore  0.01        2048   \n",
              "\n",
              "           financebench_id                                           question  \\\n",
              "0    financebench_id_03029  What is the FY2018 capital expenditure amount ...   \n",
              "1    financebench_id_04672  Assume that you are a public equities analyst....   \n",
              "2    financebench_id_00499  Is 3M a capital-intensive business based on FY...   \n",
              "3    financebench_id_01226  What drove operating margin change as of FY202...   \n",
              "4    financebench_id_01865  If we exclude the impact of M&A, which segment...   \n",
              "..                     ...                                                ...   \n",
              "145  financebench_id_00215  Is Verizon a capital intensive business based ...   \n",
              "146  financebench_id_00566  Has Verizon increased its debt on balance shee...   \n",
              "147  financebench_id_06247  What is FY2018 days payable outstanding (DPO) ...   \n",
              "148  financebench_id_04784  Based on the information provided primarily in...   \n",
              "149  financebench_id_06741  What is the FY2018 - FY2020 3 year average una...   \n",
              "\n",
              "                                           gold_answer  \\\n",
              "0                                             $1577.00   \n",
              "1                                                $8.70   \n",
              "2    No, the company is managing its CAPEX and Fixe...   \n",
              "3    Operating Margin for 3M in FY2022 has decrease...   \n",
              "4     The consumer segment shrunk by 0.9% organically.   \n",
              "..                                                 ...   \n",
              "145  Yes. Verizon's capital intensity ratio was app...   \n",
              "146      No. Verizon's debt decreased by $229 million.   \n",
              "147                                              42.69   \n",
              "148                                               0.2%   \n",
              "149                                               6.2%   \n",
              "\n",
              "                                          model_answer  \\\n",
              "0    The FY2018 capital expenditure amount for 3M i...   \n",
              "1    The year-end FY2018 net property, plant, and e...   \n",
              "2    Yes, 3M can be considered a capital-intensive ...   \n",
              "3    The operating margin for 3M as of FY2022 was i...   \n",
              "4    Excluding the impact of mergers and acquisitio...   \n",
              "..                                                 ...   \n",
              "145  Yes, Verizon is a capital-intensive business b...   \n",
              "146  Yes, Verizon has increased its debt on the bal...   \n",
              "147  To calculate the Days Payable Outstanding (DPO...   \n",
              "148  To calculate the change in unadjusted operatin...   \n",
              "149  To calculate the FY2018 - FY2020 3-year averag...   \n",
              "\n",
              "                                   retrieved_documents  \n",
              "0    [page_content='478 \\n— \\nOther — net\\n1 \\n31 \\...  \n",
              "1    [page_content='value at both December 31, 2018...  \n",
              "2    [page_content='In 2022, 3M expended approximat...  \n",
              "3    [page_content='Additional information about re...  \n",
              "4    [page_content='in the third quarter of 2022.\\n...  \n",
              "..                                                 ...  \n",
              "145  [page_content='Capital Expenditures\\n$23,087\\n...  \n",
              "146  [page_content='(3) We believe that this measur...  \n",
              "147  [page_content='As of March 28, 2018 , there we...  \n",
              "148  [page_content='$\\n500,343\\n$\\n485,873\\n$\\n482,...  \n",
              "149  [page_content='$\\n500,343\\n$\\n485,873\\n$\\n482,...  \n",
              "\n",
              "[150 rows x 10 columns]"
            ]
          }
        }
      ],
      "id": "b6035fc4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}